{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE \n",
    "# 1) Collect tweets Tom Van Grieken \n",
    "# 2) Natural language processing and bag of words\n",
    "# 3) Sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT TWEETS with Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twitter in c:\\programdata\\anaconda3\\lib\\site-packages (1.18.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install twitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consumer key, consumer secret, access token, access secret\n",
    "#request keys via Twitter Developer Account: https://developer.twitter.com/en\n",
    "\n",
    "ckey=\"FaImCBltJWhwCvN7U0G1NXRzl\"\n",
    "csecret=\"Rdvfi6dNerWCtH5TcBgTgbKSCXSBlDA2fzW9SjG80xGCJn8dIG\"\n",
    "atoken=\"1215563872796585984-i9tsQb4eHm9pGOjhsbrsRFFDBU8OHv\"\n",
    "asecret=\"JkgcK8FnbknuO15ZC9WAsPnkH8cma3mUVJ9k87gFVUYVf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter(auth = OAuth(atoken, asecret, ckey, csecret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts=twitter.statuses.user_timeline(screen_name=\"tomvangrieken\", count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "tweets = []\n",
    "dates = []\n",
    "for p in posts:\n",
    "    tweets.append(p[\"text\"])\n",
    "    dates.append(p[\"created_at\"])\n",
    "output=zip(dates,tweets)\n",
    "with open(\"tweetswithdate.csv\", mode=\"w\", encoding=\"utf-8\") as fo:\n",
    "    writer=csv.writer(fo)\n",
    "    writer.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NATURAL LANGUAGE PROCESSING with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie deze crisis absoluut niet mag betalen is de gewone Vlaming. Die heeft al de bankencrisis van 2008 moeten betalen en de immigratiefactuur. Hij gaat niet nog eens de coronafactuur daarbovenop krijgen.\n"
     ]
    }
   ],
   "source": [
    "tweet = (\"Wie deze crisis absoluut niet mag betalen is de gewone Vlaming. Die heeft al de bankencrisis van 2008 moeten betalen en de immigratiefactuur. Hij gaat niet nog eens de coronafactuur daarbovenop krijgen.\") \n",
    "print (tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie deze crisis absoluut niet mag betalen is de gewone Vlaming Die heeft al de bankencrisis van 2008 moeten betalen en de immigratiefactuur Hij gaat niet nog eens de coronafactuur daarbovenop krijgen\n"
     ]
    }
   ],
   "source": [
    "tweet_NLP = ''.join([x for x in tweet if x not in string.punctuation])\n",
    "print(tweet_NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wie deze crisis absoluut niet mag betalen is de gewone vlaming die heeft al de bankencrisis van 2008 moeten betalen en de immigratiefactuur hij gaat niet nog eens de coronafactuur daarbovenop krijgen\n"
     ]
    }
   ],
   "source": [
    "tweet_NLP = tweet_NLP.lower()\n",
    "print(tweet_NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wie', 'deze', 'crisis', 'absoluut', 'niet', 'mag', 'betalen', 'is', 'de', 'gewone', 'vlaming', 'die', 'heeft', 'al', 'de', 'bankencrisis', 'van', '2008', 'moeten', 'betalen', 'en', 'de', 'immigratiefactuur', 'hij', 'gaat', 'niet', 'nog', 'eens', 'de', 'coronafactuur', 'daarbovenop', 'krijgen']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "tweets_tokens = word_tokenize(tweet_NLP, language='dutch')\n",
    "print(tweets_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'en',\n",
       " 'van',\n",
       " 'ik',\n",
       " 'te',\n",
       " 'dat',\n",
       " 'die',\n",
       " 'in',\n",
       " 'een',\n",
       " 'hij',\n",
       " 'het',\n",
       " 'niet',\n",
       " 'zijn',\n",
       " 'is',\n",
       " 'was',\n",
       " 'op',\n",
       " 'aan',\n",
       " 'met',\n",
       " 'als',\n",
       " 'voor',\n",
       " 'had',\n",
       " 'er',\n",
       " 'maar',\n",
       " 'om',\n",
       " 'hem',\n",
       " 'dan',\n",
       " 'zou',\n",
       " 'of',\n",
       " 'wat',\n",
       " 'mijn',\n",
       " 'men',\n",
       " 'dit',\n",
       " 'zo',\n",
       " 'door',\n",
       " 'over',\n",
       " 'ze',\n",
       " 'zich',\n",
       " 'bij',\n",
       " 'ook',\n",
       " 'tot',\n",
       " 'je',\n",
       " 'mij',\n",
       " 'uit',\n",
       " 'der',\n",
       " 'daar',\n",
       " 'haar',\n",
       " 'naar',\n",
       " 'heb',\n",
       " 'hoe',\n",
       " 'heeft',\n",
       " 'hebben',\n",
       " 'deze',\n",
       " 'u',\n",
       " 'want',\n",
       " 'nog',\n",
       " 'zal',\n",
       " 'me',\n",
       " 'zij',\n",
       " 'nu',\n",
       " 'ge',\n",
       " 'geen',\n",
       " 'omdat',\n",
       " 'iets',\n",
       " 'worden',\n",
       " 'toch',\n",
       " 'al',\n",
       " 'waren',\n",
       " 'veel',\n",
       " 'meer',\n",
       " 'doen',\n",
       " 'toen',\n",
       " 'moet',\n",
       " 'ben',\n",
       " 'zonder',\n",
       " 'kan',\n",
       " 'hun',\n",
       " 'dus',\n",
       " 'alles',\n",
       " 'onder',\n",
       " 'ja',\n",
       " 'eens',\n",
       " 'hier',\n",
       " 'wie',\n",
       " 'werd',\n",
       " 'altijd',\n",
       " 'doch',\n",
       " 'wordt',\n",
       " 'wezen',\n",
       " 'kunnen',\n",
       " 'ons',\n",
       " 'zelf',\n",
       " 'tegen',\n",
       " 'na',\n",
       " 'reeds',\n",
       " 'wil',\n",
       " 'kon',\n",
       " 'niets',\n",
       " 'uw',\n",
       " 'iemand',\n",
       " 'geweest',\n",
       " 'andere']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crisis', 'absoluut', 'mag', 'betalen', 'gewone', 'vlaming', 'bankencrisis', '2008', 'moeten', 'betalen', 'immigratiefactuur', 'gaat', 'coronafactuur', 'daarbovenop', 'krijgen']\n"
     ]
    }
   ],
   "source": [
    "stop_words_nl = set(stopwords.words(\"dutch\"))\n",
    "filtered_tweets = [w for w in tweets_tokens if not w in stop_words_nl]\n",
    "print(filtered_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "ss_nl = SnowballStemmer\n",
    "ss_nl = SnowballStemmer('dutch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crisis', 'absolut', 'mag', 'betal', 'gewon', 'vlaming', 'bankencrisis', '2008', 'moet', 'betal', 'immigratiefactur', 'gat', 'coronafactur', 'daarbovenop', 'krijg']\n"
     ]
    }
   ],
   "source": [
    "stemmer_tweets = [ss_nl.stem(i) for i in filtered_tweets]\n",
    "print(stemmer_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2008</th>\n",
       "      <th>absolut</th>\n",
       "      <th>bankencrisis</th>\n",
       "      <th>betal</th>\n",
       "      <th>coronafactur</th>\n",
       "      <th>crisis</th>\n",
       "      <th>daarbovenop</th>\n",
       "      <th>gat</th>\n",
       "      <th>gewon</th>\n",
       "      <th>immigratiefactur</th>\n",
       "      <th>krijg</th>\n",
       "      <th>mag</th>\n",
       "      <th>moet</th>\n",
       "      <th>vlaming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2008  absolut  bankencrisis  betal  coronafactur  crisis  daarbovenop  \\\n",
       "0      0        0             0      0             0       1            0   \n",
       "1      0        1             0      0             0       0            0   \n",
       "2      0        0             0      0             0       0            0   \n",
       "3      0        0             0      1             0       0            0   \n",
       "4      0        0             0      0             0       0            0   \n",
       "5      0        0             0      0             0       0            0   \n",
       "6      0        0             1      0             0       0            0   \n",
       "7      1        0             0      0             0       0            0   \n",
       "8      0        0             0      0             0       0            0   \n",
       "9      0        0             0      1             0       0            0   \n",
       "10     0        0             0      0             0       0            0   \n",
       "11     0        0             0      0             0       0            0   \n",
       "12     0        0             0      0             1       0            0   \n",
       "13     0        0             0      0             0       0            1   \n",
       "14     0        0             0      0             0       0            0   \n",
       "\n",
       "    gat  gewon  immigratiefactur  krijg  mag  moet  vlaming  \n",
       "0     0      0                 0      0    0     0        0  \n",
       "1     0      0                 0      0    0     0        0  \n",
       "2     0      0                 0      0    1     0        0  \n",
       "3     0      0                 0      0    0     0        0  \n",
       "4     0      1                 0      0    0     0        0  \n",
       "5     0      0                 0      0    0     0        1  \n",
       "6     0      0                 0      0    0     0        0  \n",
       "7     0      0                 0      0    0     0        0  \n",
       "8     0      0                 0      0    0     1        0  \n",
       "9     0      0                 0      0    0     0        0  \n",
       "10    0      0                 1      0    0     0        0  \n",
       "11    1      0                 0      0    0     0        0  \n",
       "12    0      0                 0      0    0     0        0  \n",
       "13    0      0                 0      0    0     0        0  \n",
       "14    0      0                 0      1    0     0        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "d = cv.fit_transform(stemmer_tweets)\n",
    "pd.DataFrame(d.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 14 samples and 15 outcomes>\n",
      "[('betal', 2), ('crisis', 1), ('absolut', 1), ('mag', 1), ('gewon', 1)]\n",
      "dict_keys(['crisis', 'absolut', 'mag', 'betal', 'gewon', 'vlaming', 'bankencrisis', '2008', 'moet', 'immigratiefactur', 'gat', 'coronafactur', 'daarbovenop', 'krijg'])\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "all_words = nltk.FreqDist(stemmer_tweets)\n",
    "print(all_words) #We get the number of unique words (samples) and general words (outcomes)\n",
    "print(all_words.most_common(5)) #We get the most common words\n",
    "print(all_words.keys()) #We let the unique words of the distribution\n",
    "print(len(all_words.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT ANALYSIS (as a dictionary approach) with Pattern for Dutch language (https://github.com/clips/pattern/wiki/pattern-nl)\n",
    "# Dictionary build based on product reviews \n",
    "# Function returns (polarity, subjectivity)-tuple for given sentence/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.nl import sentiment as sentiment_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie deze crisis absoluut niet mag betalen is de gewone Vlaming. Die heeft al de bankencrisis van 2008 moeten betalen en de immigratiefactuur. Hij gaat niet nog eens de coronafactuur daarbovenop krijgen.\n",
      "by Tom Van Grieken, president Vlaams Belang\n",
      "In dutch\n",
      "(0.06666666666666667, 0.6)\n"
     ]
    }
   ],
   "source": [
    "print(tweet)\n",
    "print(\"by Tom Van Grieken, president Vlaams Belang\")\n",
    "print(\"In dutch\")\n",
    "print(sentiment_nl(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: Dictionary approach needs to be adjusted toward corpus at hand\n",
    "# Dictionary constructed based on product reviews not suited for the analysis of immigration-related tweets\n",
    "# Build your own dictionary, for example via supervised machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie review 'Ballerina'\n",
      "In dutch\n",
      "(0.5333333333333333, 0.7666666666666666)\n"
     ]
    }
   ],
   "source": [
    "review = (\"Franse animatiefilm over een jong weesmeisje dat ervan droomt ballerina te worden, ziet er prachtig uit, maar mist een solide verhaal.\")\n",
    "print(\"Movie review 'Ballerina'\")\n",
    "print(\"In dutch\")\n",
    "print(sentiment_nl(review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
